{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table Detection</h1>\n",
    "\n",
    "- Steps for table detection\n",
    "    - First step is to convert image into binary image.\n",
    "    - Copy the image for horizontal line detection and vertical line detection using morphological operations.\n",
    "    - And detect horizontal line and saved it horizontal image.\n",
    "    - And detect vertical line and saved it vertical image.\n",
    "    - Add both vertical image and horizontal image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>1. Binary Conversion</center></h1>\n",
    "\n",
    "- To convert our image to black and white, we will apply the thresholding operation. To do it, we need to call the threshold function of the cv2 module.\n",
    "\n",
    "- If pixel value is greater than a threshold value, it is assigned one value (may be white), else it is assigned another value (may be black). The function used is cv2.threshold. First argument is the source image, which should be a grayscale image. Second argument is the threshold value which is used to classify the pixel values. Third argument is the maxVal which represents the value to be given if pixel value is more than (sometimes less than) the threshold value. \n",
    "\n",
    "\n",
    "OpenCV provides different styles of thresholding and it is decided by the fourth parameter of the function. Different types are:\n",
    "\n",
    "- cv2.THRESH_BINARY\n",
    "- cv2.THRESH_BINARY_INV\n",
    "- cv2.THRESH_TRUNC\n",
    "- cv2.THRESH_TOZERO\n",
    "- cv2.THRESH_TOZERO_INV\n",
    "\n",
    "\n",
    "<h2>cv2.THRESH_BINARY</h2>\n",
    "\n",
    "- If the intensity of the pixel src(x,y) is higher than thresh, then the new pixel intensity is set to a MaxVal. Otherwise, the pixels are set to 0.\n",
    "\n",
    "![Image of Yaktocat](https://docs.opencv.org/2.4.13.7/_images/math/427876886dcab7b066dec1c5a9ab2ef1b3edfa5c.png)\n",
    "\n",
    "<h2>cv2.THRESH_BINARY_INV</h2>\n",
    "\n",
    "- If the intensity of the pixel src(x,y) is higher than thresh, then the new pixel intensity is set to a 0. Otherwise, it is set to MaxVal.\n",
    "\n",
    "![Image of Yaktocat](https://docs.opencv.org/2.4.13.7/_images/math/d1794a6df898462093e5d8666e791f61b4d1ec6f.png)\n",
    "\n",
    "<h2>cv2.THRESH_TRUNC</h2>\n",
    "\n",
    "- If the intensity of the pixel src(x,y) is higher than thresh, then the new pixel intensity is set to a 0. Otherwise, it is set to MaxVal.\n",
    "\n",
    "![Image of Yaktocat](https://docs.opencv.org/2.4.13.7/_images/math/85cd5dfea2f25f50640e7555c4019829859ff661.png)\n",
    "\n",
    "<h2>cv2.THRESH_TOZERO</h2>\n",
    "\n",
    "- If src(x,y) is lower than thresh, the new pixel value will be set to 0.\n",
    "\n",
    "![Image of Yaktocat](https://docs.opencv.org/2.4.13.7/_images/math/c42e93ea5c713fb2fca2605fa03ccbdf15a98d16.png)\n",
    "\n",
    "\n",
    "<h2>cv2.THRESH_TOZERO_INV</h2>\n",
    "\n",
    "- If src(x,y) is greater than thresh, the new pixel value will be set to 0.\n",
    "\n",
    "![Image of Yaktocat](https://docs.opencv.org/2.4.13.7/_images/math/6729a7b61fa189e9ad1a365aa5eb9290b70b023e.png)\n",
    "\n",
    "\n",
    "\n",
    "<h2>Adaptive Thresholding</h2>\n",
    "\n",
    "- we used a global value as threshold value. But it may not be good in all the conditions where image has different lighting conditions in different areas. In that case, we go for adaptive thresholding. In this, the algorithm calculate the threshold for a small regions of the image. So we get different thresholds for different regions of the same image and it gives us better results for images with varying illumination.\n",
    "\n",
    "- It has three ‘special’ input params and only one output argument.\n",
    "\n",
    "- Adaptive Method - It decides how thresholding value is calculated.\n",
    "    - cv2.ADAPTIVE_THRESH_MEAN_C : threshold value is the mean of neighbourhood area.\n",
    "    - cv2.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window.\n",
    "\n",
    "\n",
    "Syntax: cv2.adaptiveThreshold(source, maxVal, adaptiveMethod, thresholdType, blocksize, constant)\n",
    "\n",
    "- Parameters:\n",
    "    - source: Input Image array(Single-channel, 8-bit or floating-point)\n",
    "    - maxVal: Maximum value that can be assigned to a pixel.\n",
    "    - adaptiveMethod: Adaptive method decides how threshold value is calculated.\n",
    "\n",
    "        - cv2.ADAPTIVE_THRESH_MEAN_C: Threshold Value = (Mean of the neighbourhood area values – constant value). In other words, it is the mean of the blockSize×blockSize neighborhood of a point minus constant.\n",
    "        - cv2.ADAPTIVE_THRESH_GAUSSIAN_C: Threshold Value = (Gaussian-weighted sum of the neighbourhood values – constant value). In other words, it is a weighted sum of the blockSize×blockSize neighborhood of a point minus constant.\n",
    "\n",
    "    - thresholdType: The type of thresholding to be applied.\n",
    "    - blockSize: Size of a pixel neighborhood that is used to calculate a threshold value.\n",
    "    - constant: A constant value that is subtracted from the mean or weighted sum of the neighbourhood pixels.\n",
    "    \n",
    "    \n",
    "                thresh1 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                                          cv2.THRESH_BINARY, 199, 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>2. Morphological Operations</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "\n",
    "\n",
    "def binary(image):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    test_imgThresh = cv2.adaptiveThreshold(image,                           \n",
    "                                      255,                                  \n",
    "                                      cv2.ADAPTIVE_THRESH_GAUSSIAN_C,       \n",
    "                                      cv2.THRESH_BINARY_INV,                \n",
    "                                      11,                                   \n",
    "                                      2)\n",
    "    return test_imgThresh\n",
    "\n",
    "\n",
    "\n",
    "# Read image\n",
    "image_table = cv2.imread(\"inputs//table1.png\",cv2.IMREAD_GRAYSCALE)\n",
    "thresh_img = binary(image_table)\n",
    "cv2.imshow(\"Binary Image\",thresh_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_structure_element(width,height):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    structure_element = cv2.getStructuringElement(cv2.MORPH_RECT,(width,height))\n",
    "    return structure_element\n",
    "\n",
    "\n",
    "# copying image for horizontal and vertical line detection\n",
    "h_img = thresh_img.copy()\n",
    "v_img = thresh_img.copy()\n",
    "\n",
    "\n",
    "# h_size is to create StructuringElement for horizontal line\n",
    "scale = 15\n",
    "h_size = int(h_img.shape[1]/scale)\n",
    "structure_element = get_structure_element(h_size,1)\n",
    "structure_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Morphological Transformations</h1>\n",
    "\n",
    "- Morphological transformations are some simple operations based on the image shape. It is normally performed on binary images. It needs two inputs, one is our original image, second one is called structuring element or kernel which decides the nature of operation. \n",
    "    - Erosion\n",
    "    - Dilation\n",
    "    - Opening\n",
    "    - Claosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erosion**\n",
    "- It erodes away the boundaries of foreground object (Always try to keep foreground in white). So what does it do? The kernel slides through the image (as in 2D convolution). A pixel in the original image (either 1 or 0) will be considered 1 only if all the pixels under the kernel is 1, otherwise it is eroded (made to zero).\n",
    "- So what happends is that, all the pixels near boundary will be discarded depending upon the size of kernel. So the thickness or size of the foreground object decreases or simply white region decreases in the image. It is useful for removing small white noises (as we have seen in colorspace chapter), detach two connected objects etc.\n",
    "\n",
    "**Dilation**\n",
    "- It is just opposite of erosion. Here, a pixel element is ‘1’ if atleast one pixel under the kernel is ‘1’. So it increases the white region in the image or size of foreground object increases. Normally, in cases like noise removal, erosion is followed by dilation. Because, erosion removes white noises, but it also shrinks our object. So we dilate it. Since noise is gone, they won’t come back, but our object area increases. It is also useful in joining broken parts of an object.\n",
    "\n",
    "**Opening**\n",
    "- Opening is just another name of erosion followed by dilation. It is useful in removing noise, as we explained above. Here we use the function, cv2.morphologyEx()\n",
    "        \n",
    "            opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "<img src = \"https://opencv-python-tutroals.readthedocs.io/en/latest/_images/opening.png\">\n",
    "    \n",
    "**Closing**\n",
    "- Closing is reverse of Opening, Dilation followed by Erosion. It is useful in closing small holes inside the foreground objects, or small black points on the object.\n",
    "            \n",
    "            closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "<img src = \"https://opencv-python-tutroals.readthedocs.io/en/latest/_images/closing.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_lines(image,kernal,iterations = 1):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    h_erode_img = cv2.erode(image,kernal,iterations)\n",
    "    h_dilate_img = cv2.dilate(h_erode_img,kernal,iterations)\n",
    "    return h_dilate_img\n",
    "\n",
    "\n",
    "horizontal_line = detect_lines(h_img,structure_element)\n",
    "cv2.imshow(\"Horizontal lines\",horizontal_line)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v_size is to create StructuringElement for vertical line\n",
    "v_size = int(v_img.shape[0] / scale)\n",
    "structure_element = get_structure_element(1,v_size)\n",
    "vertical_line = detect_lines(h_img,structure_element)\n",
    "cv2.imshow(\"Vertical lines\",vertical_line)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "## Image shape will returns rows, columns and number of dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = horizontal_line + vertical_line\n",
    "cv2.imshow(\"Table image\",table)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Contours</h1>\n",
    "\n",
    "- Contours are defined as the line joining all the points along the boundary of an image that are having the same intensity. Contours come handy in shape analysis, finding the size of the object of interest, and object detection.\n",
    "\n",
    "- OpenCV has findContour() function that helps in extracting the contours from the image. It works best on binary images.\n",
    "\n",
    "**Contours Approximation Method** –\n",
    "- Above, we see that contours are the boundaries of a shape with the same intensity. It stores the (x, y) coordinates of the boundary of a shape. But does it store all the coordinates? That is specified by this contour approximation method.\n",
    "- If we pass cv2.CHAIN_APPROX_NONE, all the boundary points are stored. But actually, do we need all the points? For eg, if we have to find the contour of a straight line. We need just two endpoints of that line. This is what cv2.CHAIN_APPROX_SIMPLE does. It removes all redundant points and compresses the contour, thereby saving memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getcodeinits(image):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    npaContours, npaHierarchy = cv2.findContours(image,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    codeinits=[]\n",
    "    for npaContour in npaContours:\n",
    "        [intX, intY, intW, intH] = cv2.boundingRect(npaContour)\n",
    "        codeinits.append([intX, intY, intW, intH])\n",
    "        \n",
    "    return codeinits\n",
    "\n",
    "\n",
    "# Black color in BGR \n",
    "color = (0, 0, 0) \n",
    "   \n",
    "# Line thickness of -1 px \n",
    "# Thickness of -1 will fill the entire shape \n",
    "thickness = 2\n",
    "\n",
    "\n",
    "codeinits = getcodeinits(table)\n",
    "\n",
    "for intX, intY, intW, intH in codeinits:\n",
    "    image_table = cv2.rectangle(image_table, (intX,intY), (intX+intW,intY+intH), color, thickness) \n",
    "    \n",
    "    \n",
    "cv2.imshow(\"Binary Image\",image_table)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "outdir = os.path.join(\".\",\"outputs\")\n",
    "try:  \n",
    "    os.mkdir(outdir)  \n",
    "except OSError as error:  \n",
    "    pass\n",
    "\n",
    "cv2.imwrite(os.path.join(outdir,\"table1.png\"),image_table)\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
